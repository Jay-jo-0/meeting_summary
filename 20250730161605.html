<!DOCTYPE html>
<html lang="ko">
<head>
<style>
ul {
    margin-left: 10px;
    padding-left: 20px;
}
li {
    margin-left: 0;
    padding-left: 0;
}
</style>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>대신증권 AI 도입 회의록</title>
    <style>
        body {
            font-family: 'Malgun Gothic', 'Apple SD Gothic Neo', sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f9f9f9;
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        h1 {
            font-size: 2.2em;
            color: #2c3e50;
            text-align: center;
            margin-bottom: 30px;
            border-bottom: 3px solid #3498db;
            padding-bottom: 15px;
        }
        h2 {
            font-size: 1.8em;
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
            border-left: 5px solid #3498db;
            padding-left: 10px;
        }
        h3 {
            font-size: 1.4em;
            color: #2980b9;
            margin-top: 30px;
            margin-bottom: 15px;
            border-bottom: 1px dashed #ccc;
            padding-bottom: 5px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 25px;
            font-size: 0.95em;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #ecf0f1;
            color: #2c3e50;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #f5f5f5;
        }
        ul, ol {
            margin-bottom: 20px;
            padding-left: 25px;
        }
        li {
            margin-bottom: 8px;
        }
        strong {
            color: #e74c3c;
        }
        .highlight {
            background-color: #ecf0f1;
            padding: 15px;
            border-left: 5px solid #2ecc71;
            margin-bottom: 25px;
            font-size: 1em;
        }
        .note {
            background-color: #fcf8e3;
            border-left: 5px solid #f39c12;
            padding: 15px;
            margin-top: 25px;
            margin-bottom: 25px;
            font-size: 0.95em;
            color: #6a5300;
        }
        .evaluation {
            background-color: #e8f5e9;
            border-left: 5px solid #4CAF50;
            padding: 15px;
            margin-top: 30px;
            font-size: 1em;
            color: #2e7d32;
        }

        @media screen and (max-width: 768px) {
            body {
                padding: 10px;
            }
            .container {
                padding: 15px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 20px;
            }
            h2 {
                font-size: 1.5em;
                margin-top: 30px;
            }
            h3 {
                font-size: 1.2em;
                margin-top: 20px;
            }
            table, th, td {
                font-size: 0.85em;
                padding: 8px;
            }
        }

        @media screen and (max-width: 480px) {
            h1 {
                font-size: 1.5em;
            }
            h2 {
                font-size: 1.3em;
            }
            h3 {
                font-size: 1.1em;
            }
            .container {
                padding: 10px;
            }
            table, th, td {
                font-size: 0.8em;
                padding: 6px;
                display: block; /* Stacks table cells on very small screens */
                width: 100%;
                box-sizing: border-box;
            }
            th {
                text-align: center;
            }
            td:before {
                content: attr(data-label);
                font-weight: bold;
                display: inline-block;
                width: 80px; /* Adjust as needed */
            }
            tr {
                margin-bottom: 10px;
                display: block;
                border: 1px solid #ddd;
                border-radius: 5px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>대신증권 AI 도입 회의록</h1>

        <h2>회의 개요 및 핵심 요약</h2>
        <table>
            <thead>
                <tr>
                    <th>항목</th>
                    <th>내용</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td data-label="회의 주제"><strong>회의 주제</strong></td>
                    <td data-label="내용">아이메코 AI 에이전트 및 금융 AI 플랫폼 개발 브리핑 및 대신증권 AI 도입 방안 논의</td>
                </tr>
                <tr>
                    <td data-label="일시"><strong>일시</strong></td>
                    <td data-label="내용">미정 (스크립트 내 미기재)</td>
                </tr>
                <tr>
                    <td data-label="장소"><strong>장소</strong></td>
                    <td data-label="내용">미정 (스크립트 내 미기재)</td>
                </tr>
                <tr>
                    <td data-label="참석자"><strong>참석자</strong></td>
                    <td data-label="내용">
                        <ul>
                            <li><strong>아이메코:</strong> 장명훈 주임 (AI TF), 기타 관계자</li>
                            <li><strong>대신증권:</strong> AI TF 관계자, 기타 관계자</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td data-label="주요 논의 사항"><strong>주요 논의 사항</strong></td>
                    <td data-label="내용">
                        <ul>
                            <li>아이메코의 AI 에이전트 및 금융 AI 플랫폼(XAIS) 소개</li>
                            <li>AI 기술 발전 단계 및 핵심 배경 지식 (AI 에이전트, MCP, RAG) 설명</li>
                            <li>XAIS의 시스템 구성, 핵심 기능 (에이전트 빌더, 워크플로우 빌더) 및 데모 시연</li>
                            <li>XAIS의 대신증권 업무 적용 방안 및 자체 LLM 구축 가이드 제시</li>
                            <li>대신증권의 AI 도입 관련 현황 및 고민 사항 공유 (망분리, 데이터 정책, 서비스화 난이도)</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td data-label="회의 목표"><strong>회의 목표</strong></td>
                    <td data-label="내용">아이메코의 AI 솔루션에 대한 이해 증진 및 대신증권의 AI 도입 방향성 모색</td>
                </tr>
            </tbody>
        </table>

        <div class="highlight">
            <h3>회의 핵심 요약</h3>
            <p>본 회의는 아이메코의 AI TF 장명훈 주임이 대신증권 관계자들에게 아이메코의 <strong>AI 에이전트 및 금융 AI 플랫폼 'XAIS'</strong>에 대해 브리핑하고, 대신증권의 AI 도입 방안을 논의하는 자리였습니다. 아이메코는 AI 기술의 발전 단계와 AI 에이전트, MCP, RAG 등 핵심 개념을 상세히 설명하며, 자사 플랫폼 XAIS의 기능과 업무 적용 사례를 데모와 함께 제시했습니다. 특히, <strong>에이전트 빌더와 워크플로우 빌더를 통해 복잡한 업무를 자동화하고 효율성을 높일 수 있음</strong>을 강조했습니다. 대신증권 측은 망분리 환경에서의 AI 도입, 데이터 정책, 그리고 실제 서비스화의 난이도에 대한 현실적인 고민을 공유하며, 아이메코와의 협업 가능성을 탐색했습니다. 양측은 금융권 특성을 고려한 <strong>단계적인 AI 도입 전략</strong>의 필요성에 공감대를 형성했습니다.</p>
        </div>

        <h2>세부 회의 내용</h2>

        <h3>1. 아이메코 회사 소개 및 AI 에이전트 개요</h3>
        <ul>
            <li><strong>회사 소개:</strong> 아이메코는 로우 레이턴시 기술, 채널 접속 솔루션, 대내외 중계 시스템, 네트워크 통합 역량을 기반으로 효율적이고 안정적인 데이터 인프라를 구축한 기업입니다. 현재는 <strong>금융 AI 산업을 이끄는 AI 선도기업</strong>으로 발전하고 있습니다.</li>
            <li><strong>AI 기술 발전 단계:</strong>
                <ol>
                    <li><strong>퍼셉션 AI:</strong> 사람의 눈과 귀 역할 (이미지/음성 인식).</li>
                    <li><strong>생성형 AI (Generative AI):</strong> 학습 내용을 바탕으로 새로운 것을 생성.</li>
                    <li><strong>AI 에이전트:</strong> 특정 목표를 가지고 <strong>스스로 판단하고 행동하는 능력</strong>까지 갖춘 AI. (예: 웹 검색 도구를 사용하여 정보 수집 후 응답 생성)</li>
                    <li><strong>피지컬 AI:</strong> AI 에이전트에 물리적 신체가 합쳐진 형태 (예: 자율주행 자동차).</li>
                </ol>
            </li>
            <li><strong>모던 AI 기술 스택:</strong> 인프라, 데이터, 모델, AI 미들웨어, 애플리케이션의 5가지 계층으로 구성됩니다.
                <ul>
                    <li><strong>인프라:</strong> 네트워크, AI 반도체(NPU/GPU), 온프레미스/클라우드 구축.</li>
                    <li><strong>데이터:</strong> 데이터 소스, 파이프라인, RAG를 위한 벡터 데이터베이스.</li>
                    <li><strong>모델:</strong> 파운데이션 모델, MLOps 툴, 추론/학습 서버.</li>
                    <li><strong>AI 미들웨어:</strong> AI/머신러닝 프레임워크 기반 에이전트, MCP, RAG 애플리케이션.</li>
                    <li><strong>애플리케이션:</strong> 사용자 상호작용 프론트엔드, AI 앱 미들웨어와 프론트엔드 중개 백엔드.</li>
                </ul>
            </li>
        </ul>

        <h3>2. 핵심 배경 지식 상세 설명</h3>
        <ul>
            <li><strong>AI 에이전트:</strong>
                <ul>
                    <li><strong>정의:</strong> 생성형 AI의 판단 능력, 추론 및 행동 능력, 도구 사용을 결합한 것입니다.</li>
                    <li><strong>특징:</strong> 단일 작업만 가능한 생성형 AI와 달리, AI 에이전트는 <strong>여러 단계로 이뤄진 복잡한 작업 수행이 가능</strong>하며, 외부 도구(웹 검색 API, 파이썬 스크립트, 사내 기존 시스템 등)를 활용하여 정보를 수집하거나 작업을 처리할 수 있습니다.</li>
                </ul>
            </li>
            <li><strong>MCP (Model Context Protocol):</strong>
                <ul>
                    <li><strong>정의:</strong> 에이전트와 외부 시스템이 소통하기 위해 약속된 규칙 (클로드의 앤트로픽사 제안, 챗GPT 오픈AI 도입).</li>
                    <li><strong>장점:</strong> MCP 등장 이전에는 도구마다 인터페이스를 직접 개발해야 했으나, MCP 도입 후에는 <strong>새로운 툴이나 데이터 소스 추가 시 인터페이스 개발 불필요</strong> (USB C 포트 비유). 에이전트와 도구의 완벽한 분리로 유지보수 간편성 및 확장성 크게 향상.</li>
                </ul>
            </li>
            <li><strong>RAG (Retrieval-Augmented Generation):</strong>
                <ul>
                    <li><strong>정의:</strong> AI 에이전트를 위해 <strong>신뢰성 있는 외부 지식 저장소를 구축하는 방법</strong>.</li>
                    <li><strong>해결 문제:</strong>
                        <ol>
                            <li><strong>지식의 한계:</strong> LLM은 학습 데이터에 없는 최신/내부 정보(사내 정책, 기술 문서)를 알지 못함.</li>
                            <li><strong>보안 문제:</strong> 웹 검색 등 외부 도구로 사내 문서 접근 불가.</li>
                            <li><strong>데이터 형태 문제:</strong> 논문, 보고서 등 비정형 문서는 기존 RDBMS로 비효율적.</li>
                        </ol>
                    </li>
                    <li><strong>동작 원리:</strong> 사용자의 질문을 임베딩 모델로 벡터화 → 벡터 데이터베이스에서 유사도 검색 → 검색된 문서를 LLM 프롬프트에 추가(증강) → LLM이 증강된 프롬프트 기반으로 <strong>정확하고 근거 있는 답변 생성</strong>.</li>
                    <li><strong>핵심 기술:</strong> <strong>임베딩</strong> (텍스트 의미를 AI가 이해하는 숫자 좌표/벡터로 변환)과 <strong>벡터 데이터베이스</strong> (변환된 벡터 데이터 저장 및 초고속 유사 문서 검색).</li>
                </ul>
            </li>
        </ul>

        <h3>3. 레거시 AI 애플리케이션과 AI 에이전트의 차이</h3>
        <ul>
            <li><strong>레거시 AI 애플리케이션:</strong> 대부분 정해진 플로우대로 작업 진행 (단순 단방향 구조). 유연성 낮고 항상 같은 순서로 동작 (예: 챗봇, 단순 질의응답).</li>
            <li><strong>AI 에이전트:</strong> <strong>LLM이 직접 다음 행동을 계획하고 결정</strong>. 도구를 활용하여 추가 정보 검색 가능. <strong>유연하게 복잡한 문제 해결</strong> 가능. LLM 성능 향상에 힘입어 각광받고 있음 (구글, 오픈AI 상용 에이전트 및 Gemma와 같은 오픈소스 모델 성능 급격 향상).</li>
        </ul>

        <h3>4. 아이메코 AI 플랫폼 XAIS 소개</h3>
        <ul>
            <li><strong>XAIS의 목표:</strong>
                <ul>
                    <li>에이전트 및 도구의 손쉬운 생성 및 업무 적용.</li>
                    <li>생성된 에이전트를 묶어 복잡한 업무 플로우를 만들 수 있는 <strong>워크플로우 빌더</strong>.</li>
                    <li>효율적인 문서 관리를 위한 파이프라인 구축.</li>
                    <li>이러한 서비스들을 통합하여 <strong>에이전트 스튜디오</strong> 개발.</li>
                </ul>
            </li>
            <li><strong>XAIS 시스템 구성도:</strong> 프론트엔드, 에이전트 서버, 로컬 LLM 서버, MCP 서버(도구 제공), 문서 관리를 위한 DB로 구성. MCP 도구는 고객사 요구사항에 맞춰 개발 가능하도록 분리 구축.</li>
            <li><strong>XAIS 계층도:</strong> 자체 개발 엔진과 오픈소스 AI 프레임워크 기반 인프라 위에 애플리케이션 구축. 특히 에이전트 매니지 모듈, 워크플로우 모듈, 놀리지 매니지먼트 모듈을 기반으로 <strong>AI 에이전트 스튜디오</strong> 개발 중.</li>
            <li><strong>핵심 기능:</strong>
                <ul>
                    <li><strong>에이전트 빌더:</strong> 에이전트 기본 정보, LLM 모델, 역할, 목표 설정, 도구 선택을 통해 간단하게 에이전트 생성. 생성된 에이전트를 <strong>에이전트 마켓플레이스에 공유</strong>하여 전사/팀 내에서 활용 가능. (LLM 활용하여 프롬프트 자동 보완 기능 기획)</li>
                    <li><strong>워크플로우 빌더:</strong> 드래그 앤 드롭 방식으로 복잡한 업무 플로우 직접 생성. 마켓플레이스에 공유하여 사내 활용 가능.</li>
                    <li><strong>워크플로우 예시:</strong> 사용자 요청 → 플래너 에이전트 계획 수립 → 단계별 에이전트 업무 할당 및 수행 → Finalize Agent를 통한 결과물 취합 및 최종 응답 생성.</li>
                </ul>
            </li>
            <li><strong>데모 시연:</strong>
                <ul>
                    <li><strong>주식 투자 의견 보고서 생성 워크플로우:</strong> 여러 에이전트(웹 검색, 공시 정보, 차트 생성, 자료 조사)를 활용하여 최종 투자 의견 보고서 생성. (1~2분 소요)</li>
                    <li><strong>RAG 활용 이력서 평가 챗봇:</strong> 미리 구축된 가짜 이력서 및 채용 평가 기준 문서를 기반으로 질의응답. 내부 문서를 기반으로 AI가 응답 생성.</li>
                    <li><strong>PDF 문서 분석 및 요약 XAI 도구:</strong> 사내 규정, 약관 등 복잡한 PDF 문서를 분석 및 요약. 멀티 모달(텍스트, 이미지, 차트, 테이블), AI 비전, OCR, 멀티 에이전트 결합. 3단계(구조화, 분석, 해석)를 거쳐 요약 문서 생성 및 질의응답 가능. (기대 효과: 주요 데이터 시각화, 정보 접근성 향상, Q&A 시스템 통한 업무 효율성 증대, 자체 추론 서버 기반 데이터 유출 예방)</li>
                </ul>
            </li>
        </ul>

        <h3>5. 아이메코 로드맵 및 XAIS 업무 적용 방안</h3>
        <ul>
            <li><strong>로드맵:</strong> 금융 AI 특화 에이전트 프레임워크 지속 고도화, 에이전트 스튜디오를 통해 쉽고 빠르게 에이전트와 워크플로우 생성 가능한 AI 솔루션 개발. 현재 <strong>프레임워크 v1 개발 완료</strong>, <strong>v2 및 에이전트 스튜디오 완성 목표 (12월 말)</strong>.</li>
            <li><strong>XAIS 업무 적용 방안:</strong>
                <ul>
                    <li><strong>레거시 기반 문서 검색 시스템:</strong> 벡터 DB 기반 회사 지식 베이스 구축 (규정, 사규, 업무 매뉴얼 등) 및 검색/챗봇 기능 통한 업무 효율성 증대.</li>
                    <li><strong>업무 보조 AI 에이전트 개발:</strong> 에이전트 빌더를 통해 증권 뉴스 검색, 실시간 주식 가격 조회 등 다양한 에이전트 개발.</li>
                    <li><strong>복잡한 업무 자동화를 위한 워크플로우:</strong> 드래그 앤 드롭으로 증권 리서치 리포트 생성, 뉴스 기반 종목 추천 등 복잡한 작업 자동화. 각 부서별 반복 업무 자동화.</li>
                    <li><strong>사용자 편의 기능 추가.</strong></li>
                </ul>
            </li>
            <li><strong>자체 LLM 구축 시 모델 선택 가이드:</strong>
                <ul>
                    <li><strong>파라미터 크기 기준:</strong> 중형급 (30B 이하), 중대형급 (40B~150B), 대형급 (150B 이상)으로 구분.</li>
                    <li><strong>추천 모델:</strong> 하드웨어 성능, 예산, 서비스 규모(동시 사용자 수)에 따라 추천 모델 제시. (예: 100명 동시 사용자 기준 중형급 모델 사용 시 GPU 워크스테이션 4~8개 필요)</li>
                    <li><strong>속도-정확도 트레이드오프:</strong> 모델 사이즈가 커질수록 속도는 느려지지만 정확도는 향상. (GPT 미니/제미나이 플래시 모델 예시)</li>
                </ul>
            </li>
        </ul>

        <h3>6. 질의응답 (Q&A) 세션</h3>
        <ul>
            <li><strong>LLM 모델 구축 방식:</strong>
                <ul>
                    <li><strong>질문:</strong> LLM 모델을 내부 구축하는 것인지, 외부도 가능한지?</li>
                    <li><strong>답변 (아이메코):</strong> 외부 LLM 모델 사용도 가능하며, 내부에 서버가 구축되어 있다면 내부 LLM 서버와 통신하도록 모듈 개발 완료.</li>
                </ul>
            </li>
            <li><strong>프론트엔드-에이전트 서버 통신:</strong>
                <ul>
                    <li><strong>질문:</strong> 에이전트 서버와 프론트엔드 간 통신 방식은? API 형태인지, 만들기 나름인지?</li>
                    <li><strong>답변 (아이메코):</strong> 현재는 API로 구성, 추가적으로 웹 소켓도 가능. 앞단 라우터 개발을 통해 어떤 통신 방법이든 가능하도록 구현. 에이전트 서버가 백엔드 기능 및 LLM/MCP 서버 간 중개 역할 수행.</li>
                </ul>
            </li>
            <li><strong>MCP 서버 및 외부 데이터 연동:</strong>
                <ul>
                    <li><strong>질문:</strong> MCP 서버가 외부 데이터 소스(거래소, 공시 등)와 연동되는 방식은?</li>
                    <li><strong>답변 (아이메코):</strong> MCP 서버는 툴을 표현하며, 각 회사마다 툴은 다르므로 회사별로 맞춤 개발이 필요. 에이전트 엔진 및 워크플로우 엔진은 유사하게 동작.</li>
                </ul>
            </li>
            <li><strong>벡터 데이터베이스 (Qdrant) 및 RDBMS (PostgreSQL) 선택 이유:</strong>
                <ul>
                    <li><strong>질문:</strong> Qdrant와 PostgreSQL을 사용한 이유는?</li>
                    <li><strong>답변 (아이메코):</strong> <strong>Qdrant</strong>는 오픈소스이며 성능이 상위권에 위치하고 실제 사용 레퍼런스가 많아 선택. (초반에 경량화된 Faiss를 고려했으나 엔터프라이즈급에는 부적합하다고 판단). <strong>PostgreSQL</strong>은 메타데이터를 별도로 저장 관리하기 위함. 벡터 데이터는 벡터 DB에, 메타데이터는 RDBMS에 분리 저장하여 관리.</li>
                </ul>
            </li>
            <li><strong>에이전트 스튜디오 개발 현황:</strong>
                <ul>
                    <li><strong>질문:</strong> 스튜디오는 아직 개발 중인지?</li>
                    <li><strong>답변 (아이메코):</strong> 1차적으로 에이전트 및 워크플로우 엔진 개발에 집중했고, UI적인 스튜디오 부분은 현재 개발 중 (12월까지 사용자 빌드/관리/마켓플레이스 기능 완성 목표).</li>
                    <li><strong>스튜디오의 중요성:</strong> 에이전트 기술이 급부상하면서 스튜디오의 역할이 매우 중요하다고 판단. 고객이 직접 에이전트를 만들고 원하는 대로 활용할 수 있는 구조를 제공하는 것이 목표.</li>
                </ul>
            </li>
            <li><strong>멀티 에이전트 기술 검증:</strong>
                <ul>
                    <li><strong>아이메코:</strong> 에이전트 한 개는 잘 돌아가지만, 멀티 에이전트 환경에서는 기술 검증 및 최적화된 협업 에이전트 구현이 쉽지 않음. 현재 어느 정도 검증된 상태로 소개.</li>
                </ul>
            </li>
            <li><strong>증권사 협업 사례 및 망분리 환경:</strong>
                <ul>
                    <li><strong>질문:</strong> 증권사 협업 사례가 있는지? 망분리 환경에서 데이터 처리는 어떻게 하는지?</li>
                    <li><strong>답변 (아이메코):</strong> AI 관련 사업은 아직 없으나, 아이메코는 대신증권 등 증권사 풀(Pool)에 참여하며 망분리 및 금융권 시스템 현황을 잘 이해하고 있음. 벡터 DB 및 소규모 LLM은 내부 구축 가능하나, 전 직원/고객 서비스화는 어려움. 외부 LLM 사용 시 망분리 및 혁신 서비스 절차 필요. <strong>단기간에는 외부 LLM을 활용한 적용 후 점진적 확장 제안.</strong></li>
                </ul>
            </li>
            <li><strong>LLM 모델 추천 기준 상세:</strong>
                <ul>
                    <li><strong>질문:</strong> 모델 추천 기준(중형급 등)을 더 구체적으로 설명해달라. (예: 몇 개 정도 돌릴 수 있는지)</li>
                    <li><strong>답변 (아이메코):</strong> 30B(빌리언) 기준, 초당 20 토큰 정도를 한 사람이 지연 없이 처리할 수 있는 양으로 계산. 100명 동시 사용자 기준 중형급 모델 사용 시 4~8개의 GPU 워크스테이션 필요. 모델 사이즈가 클수록 하드웨어 점유율 증가.</li>
                </ul>
            </li>
            <li><strong>중국산 모델 사용에 대한 우려:</strong>
                <ul>
                    <li><strong>질문:</strong> Qwen(알리바바) 등 중국산 모델 사용 사례가 많은지? 보안 우려가 없는지?</li>
                    <li><strong>답변 (아이메코):</strong> Llama나 Qwen은 라이선스 부담 없이 사용 가능하며, 데이터 유출과 관계없음. 망분리된 로컬 환경에서 모델을 직접 서빙하면 외부 유출 가능성 낮음. 최근 한국어 처리 성능에서 Qwen이 Llama보다 앞선다는 평가도 있음. 국내 업체 중 딥시크 기반 내부 LLM 구축 제품화 사례도 있어 내부망 보안 우려 해소 가능성 언급.</li>
                </ul>
            </li>
            <li><strong>외부 CSP (Bedrock) 사용과 직접 LLM 구축의 차이:</strong>
                <ul>
                    <li><strong>질문:</strong> 클라우드 상의 관리형 서비스(예: AWS Bedrock) 사용과 직접 LLM 구축의 차이는? 컴플라이언스 조건은 어떻게 반영되는지?</li>
                    <li><strong>답변 (아이메코):</strong> Bedrock 등 CSP 사용 시 클라우드 비용이 추가되나, 파인튜닝 툴 등 편리한 기능 제공. 컴플라이언스 및 가드레일 부분은 현재 아이메코 시스템에서 직접 API 호출을 사용하고 있어, 대신증권과 같은 규제 산업 환경에서는 추가적인 고민과 반영이 필요함을 인지하고 있음.</li>
                </ul>
            </li>
            <li><strong>스튜디오 UI/UX 데모:</strong>
                <ul>
                    <li><strong>아이메코:</strong> 대시보드(활성화 에이전트, 총 대화 수, 활성 사용자), 에이전트 빌더(역할/설명/LLM 프로바이더 선택, LLM 기반 프롬프트 자동 보완 기능), 에이전트 마켓플레이스, 커스텀 툴 등록 기능 시연.</li>
                    <li><strong>워크플로우 빌더:</strong> 드래그 앤 드롭으로 시작 방식(채팅/명령어) 설정, 에이전트 추가 및 연결, 분기문(조건식 기반) 설정 기능 시연. (분기문 조건부는 LLM을 활용하여 판단하도록 기획 중)</li>
                    <li><strong>데모 과정 설명:</strong> 주식 리서치 보고서 생성 워크플로우는 여러 에이전트가 엮여 동작하며, 이력서 평가 챗봇은 RAG 기반으로 내부 문서 활용. PDF 파서는 구조화, 분석, 해석 단계를 거치며 이미지/차트/테이블 처리 및 VLLM(Vision to Language Model)을 통한 텍스트 변환 수행. 최종적으로 요약된 내용이 원본 문서의 어느 부분을 참조하는지 표기하는 기능 개발 중.</li>
                </ul>
            </li>
        </ul>

        <h2>회의 인사이트</h2>
        <div class="note">
            <p>이번 회의를 통해 <strong>AI 에이전트 기술이 단순한 질의응답을 넘어 복잡한 업무 자동화와 의사결정 지원의 핵심 동력</strong>이 될 수 있음을 명확히 이해할 수 있었습니다. 특히 아이메코의 XAIS 플랫폼은 <strong>에이전트 빌더와 워크플로우 빌더를 통해 비전문가도 쉽게 AI를 업무에 적용하고 확장할 수 있는 가능성</strong>을 제시했습니다. 이는 대신증권이 AI를 도입함에 있어 내부 역량을 강화하고, 반복적인 업무를 효율화하며, 궁극적으로는 데이터 기반의 심층적인 분석 및 리서치 역량을 확보하는 데 중요한 역할을 할 수 있을 것입니다.</p>
            <p>또한, 금융권의 특성상 <strong>망분리, 데이터 보안, 컴플라이언스 준수</strong>가 필수적인데, 아이메코가 이러한 환경에 대한 이해를 바탕으로 온프레미스 구축 및 외부 LLM 활용 전략을 제시한 점은 현실적인 도입 방안을 모색하는 데 도움이 되었습니다. 다만, 실제 서비스 적용 시 발생할 수 있는 <strong>컴플라이언스 및 가드레일 구축에 대한 구체적인 방안 마련</strong>이 선행되어야 함을 확인했습니다. 오픈소스 LLM의 한국어 처리 성능 향상과 기업용 활용 가능성은 비용 효율적인 AI 도입을 위한 긍정적인 신호로 해석됩니다.</p>
        </div>

        <h2>향후 계획 (Next Steps)</h2>
        <ol>
            <li><strong>아이메코 XAIS 기술 검토 및 추가 정보 요청:</strong>
                <ul>
                    <li>데모 시연 시 언급된 <strong>워크플로우의 비주얼 맵 또는 코드 구성 방식</strong>에 대한 추가 자료 요청 및 심층 검토.</li>
                    <li>PDF 파서의 <strong>문서 출처 표기 기능 개발 현황</strong> 및 실제 동작 방식에 대한 업데이트 요청.</li>
                </ul>
            </li>
            <li><strong>대신증권 AI 도입 마스터 플랜 구체화:</strong>
                <ul>
                    <li>현재 진행 중인 AI TF의 <strong>AI 마스터 플랜 수립</strong>을 가속화하고, 아이메코 XAIS와 같은 솔루션의 적용 가능성을 다각도로 검토.</li>
                    <li><strong>M365 파일럿 도입</strong>과 연계하여 SaaS 기반 AI 서비스 경험을 선행하고, 이를 통해 내부 AI 역량 및 활용 가능성을 탐색.</li>
                </ul>
            </li>
            <li><strong>가성비 높은 AI 도입 주제 선정:</strong>
                <ul>
                    <li>구축이 쉽고 효과가 큰 <strong>"퀵 윈(Quick Win)" 프로젝트</strong> 발굴에 집중. (예: 레거시 문서 검색 시스템 고도화, 특정 부서의 반복 업무 자동화 에이전트 개발)</li>
                    <li>데이터 정책 및 비정형 데이터 벡터화 등 <strong>기반 인프라 구축의 난이도</strong>를 고려하여 단계적인 접근 방식 수립.</li>
                </ul>
            </li>
            <li><strong>금융권 특화 AI 적용 방안 모색:</strong>
                <ul>
                    <li>망분리 환경, 데이터 유출 방지 등 <strong>금융 규제 준수</strong>를 최우선으로 고려한 AI 시스템 아키텍처 및 운영 방안 논의.</li>
                    <li>장기적으로 <strong>피시브 주문, 시장 데이터 기반 알고리즘 트레이딩 지원</strong> 등 대신증권의 핵심 업무에 AI를 접목할 수 있는 방안에 대한 지속적인 탐색 및 아이메코와의 협력 가능성 논의.</li>
                </ul>
            </li>
            <li><strong>지속적인 기술 교류:</strong> 아이메코와 대신증권 간의 정기적인 기술 교류를 통해 AI 기술 발전 동향 및 적용 사례를 공유하고, 상호 협력 방안을 지속적으로 모색.</li>
        </ol>

        <h2>회의 평가</h2>
        <div class="evaluation">
            <p>이번 회의는 아이메코의 AI 에이전트 및 금융 AI 플랫폼 XAIS에 대한 <strong>깊이 있는 이해를 제공</strong>했으며, 대신증권의 AI 도입 방향성을 설정하는 데 중요한 시사점을 주었습니다. 아이메코의 기술 브리핑은 AI 기술의 복잡한 개념을 명확하게 설명하고, 실제 데모를 통해 XAIS의 잠재력을 효과적으로 보여주었습니다. 특히, <strong>에이전트 빌더와 워크플로우 빌더의 사용자 친화적인 접근 방식</strong>은 내부 AI 역량이 부족한 기업에서도 AI를 쉽게 활용할 수 있게 할 것이라는 점에서 긍정적으로 평가됩니다.</p>
            <p>질의응답 세션에서는 대신증권의 현실적인 고민(망분리, 데이터 보안, 서비스화 난이도)이 잘 드러났으며, 아이메코가 이에 대해 금융권 환경에 대한 이해를 바탕으로 유연한 접근 방안을 제시한 점은 협업 가능성을 높였습니다. 다만, <strong>컴플라이언스 및 가드레일과 같은 규제 관련 부분에 대한 구체적인 솔루션 제시가 향후 과제</strong>로 보입니다.</p>
            <p>전반적으로 이번 회의는 대신증권이 AI 도입을 위한 <strong>전략적 방향성을 설정하고, 잠재적인 기술 파트너를 탐색하는 데 매우 유익한 시간</strong>이었습니다. 아이메코의 기술력과 금융권에 대한 이해를 바탕으로, 대신증권의 AI 도입이 성공적으로 이루어질 수 있는 기반을 마련하는 데 기여할 것으로 기대됩니다.</p>
        </div>
    </div>
</body>
</html>